{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSIRO Image2Biomass - V5: RGB+Depth Fusion Ensemble\n",
    "\n",
    "This notebook generates predictions using a **5-fold ensemble** of RGB+Depth Fusion models:\n",
    "- **Architecture**: Dual encoder (EfficientNetV2-M RGB + Depth Anything v2)\n",
    "- **Fusion**: Concatenation of RGB and depth features\n",
    "- Mean validation loss: 3.06 +/- 1.55 (MSE)\n",
    "- Image size: 384x384\n",
    "- TTA: 8 transforms (flips + rotations)\n",
    "- Biological constraints enforced in post-processing\n",
    "\n",
    "## Setup Instructions\n",
    "1. Add the model dataset (image2biomass-depth-fusion-model)\n",
    "2. Add the competition data\n",
    "3. **Set Internet to OFF** (required for submission)\n",
    "4. Run all cells to generate submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"timm version: {timm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TEST_CSV = '/kaggle/input/csiro-biomass/test.csv'\n",
    "TEST_IMG_DIR = '/kaggle/input/csiro-biomass/test'\n",
    "TRAIN_CSV = '/kaggle/input/csiro-biomass/train.csv'\n",
    "TRAIN_IMG_DIR = '/kaggle/input/csiro-biomass/train'\n",
    "\n",
    "# Model checkpoints path\n",
    "MODEL_BASE = '/kaggle/input/image2biomass-depth-fusion-model/pytorch/default/1'\n",
    "DEPTH_MODEL_PATH = f'{MODEL_BASE}/depth_anything_v2_small'\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Target names\n",
    "TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "\n",
    "# Model config\n",
    "CONFIG = {\n",
    "    'backbone': 'efficientnetv2_rw_m',\n",
    "    'depth_model': 'depth_anything_v2_small',\n",
    "    'fusion_type': 'concat',\n",
    "    'image_size': 384,\n",
    "    'batch_size': 8,\n",
    "    'num_workers': 0,\n",
    "    'dropout': 0.3\n",
    "}\n",
    "\n",
    "# Use TTA\n",
    "USE_TTA = True\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Depth Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthEstimator(nn.Module):\n",
    "    \"\"\"Wrapper for Depth Anything v2 model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, freeze=True):\n",
    "        super().__init__()\n",
    "        self.freeze = freeze\n",
    "        \n",
    "        # Load from local path\n",
    "        self.processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "        self.model = AutoModelForDepthEstimation.from_pretrained(model_path)\n",
    "        \n",
    "        if freeze:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, images):\n",
    "        B, C, H, W = images.shape\n",
    "        \n",
    "        with torch.no_grad() if self.freeze else torch.enable_grad():\n",
    "            outputs = self.model(images)\n",
    "            depth = outputs.predicted_depth\n",
    "            \n",
    "            depth = F.interpolate(\n",
    "                depth.unsqueeze(1),\n",
    "                size=(H, W),\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        depth_flat = depth.view(B, -1)\n",
    "        depth_min = depth_flat.min(dim=1, keepdim=True)[0].view(B, 1, 1, 1)\n",
    "        depth_max = depth_flat.max(dim=1, keepdim=True)[0].view(B, 1, 1, 1)\n",
    "        depth = (depth - depth_min) / (depth_max - depth_min + 1e-8)\n",
    "        \n",
    "        return depth\n",
    "\n",
    "print(\"DepthEstimator defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RGB+Depth Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBDepthFusionEncoder(nn.Module):\n",
    "    \"\"\"Dual-encoder model fusing RGB and depth features.\"\"\"\n",
    "    \n",
    "    def __init__(self, rgb_backbone, depth_model_path, fusion_type='concat',\n",
    "                 dropout=0.3, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fusion_type = fusion_type\n",
    "        self.target_names = TARGET_NAMES\n",
    "        \n",
    "        # RGB Encoder\n",
    "        self.rgb_encoder = timm.create_model(\n",
    "            rgb_backbone,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        rgb_features = self.rgb_encoder.num_features\n",
    "        \n",
    "        # Depth Estimator\n",
    "        self.depth_estimator = DepthEstimator(depth_model_path, freeze=True)\n",
    "        \n",
    "        # Depth Feature Encoder\n",
    "        self.depth_encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        depth_features = 256\n",
    "        \n",
    "        # Fusion\n",
    "        if fusion_type == 'concat':\n",
    "            fused_features = rgb_features + depth_features\n",
    "            self.fusion = nn.Identity()\n",
    "        elif fusion_type == 'add':\n",
    "            self.rgb_proj = nn.Linear(rgb_features, 512)\n",
    "            self.depth_proj = nn.Linear(depth_features, 512)\n",
    "            fused_features = 512\n",
    "        elif fusion_type == 'attention':\n",
    "            self.rgb_proj = nn.Linear(rgb_features, 512)\n",
    "            self.depth_proj = nn.Linear(depth_features, 512)\n",
    "            self.attention = nn.MultiheadAttention(512, num_heads=8, batch_first=True)\n",
    "            fused_features = 512\n",
    "        \n",
    "        # Regression heads\n",
    "        self.heads = nn.ModuleDict()\n",
    "        for target_name in self.target_names:\n",
    "            self.heads[target_name] = nn.Sequential(\n",
    "                nn.Linear(fused_features, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(64, 1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, images):\n",
    "        rgb_features = self.rgb_encoder(images)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            depth_maps = self.depth_estimator(images)\n",
    "        depth_features = self.depth_encoder(depth_maps)\n",
    "        \n",
    "        if self.fusion_type == 'concat':\n",
    "            fused = torch.cat([rgb_features, depth_features], dim=1)\n",
    "        elif self.fusion_type == 'add':\n",
    "            fused = self.rgb_proj(rgb_features) + self.depth_proj(depth_features)\n",
    "        elif self.fusion_type == 'attention':\n",
    "            rgb_proj = self.rgb_proj(rgb_features).unsqueeze(1)\n",
    "            depth_proj = self.depth_proj(depth_features).unsqueeze(1)\n",
    "            combined = torch.cat([rgb_proj, depth_proj], dim=1)\n",
    "            attended, _ = self.attention(combined, combined, combined)\n",
    "            fused = attended.mean(dim=1)\n",
    "        \n",
    "        predictions = {}\n",
    "        for target_name in self.target_names:\n",
    "            predictions[target_name] = self.heads[target_name](fused).squeeze(-1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "print(\"RGBDepthFusionEncoder defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassTestDataset(Dataset):\n",
    "    \"\"\"Test dataset for biomass prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path, img_dir, transform=None, target_stats=None):\n",
    "        self.csv_path = csv_path\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.target_stats = target_stats\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df['image_id'] = self.df['sample_id'].str.split('__').str[0]\n",
    "        self.image_ids = self.df['image_id'].unique()\n",
    "        self.image_paths = self.df.groupby('image_id')['image_path'].first().to_dict()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_filename = Path(self.image_paths[image_id]).name\n",
    "        image_path = self.img_dir / image_filename\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        return {'image': image, 'image_id': image_id}\n",
    "\n",
    "print(\"BiomassTestDataset defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TTA Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tta_transforms(image_size=384):\n",
    "    \"\"\"Get 8 TTA transforms (4 flips x 2 rotations).\"\"\"\n",
    "    transforms = []\n",
    "    \n",
    "    flip_configs = [\n",
    "        (False, False),  # No flip\n",
    "        (True, False),   # Horizontal flip\n",
    "        (False, True),   # Vertical flip\n",
    "        (True, True),    # Both flips\n",
    "    ]\n",
    "    \n",
    "    rotation_angles = [0, 90]\n",
    "    \n",
    "    for hflip, vflip in flip_configs:\n",
    "        for angle in rotation_angles:\n",
    "            aug_list = [A.Resize(image_size, image_size)]\n",
    "            \n",
    "            if hflip:\n",
    "                aug_list.append(A.HorizontalFlip(p=1.0))\n",
    "            if vflip:\n",
    "                aug_list.append(A.VerticalFlip(p=1.0))\n",
    "            if angle != 0:\n",
    "                aug_list.append(A.Rotate(limit=(angle, angle), p=1.0, border_mode=0))\n",
    "            \n",
    "            aug_list.extend([\n",
    "                A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            \n",
    "            transforms.append(A.Compose(aug_list))\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def get_val_transform(image_size=384):\n",
    "    \"\"\"Get validation transform (no augmentation).\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "if USE_TTA:\n",
    "    tta_transforms = get_tta_transforms(CONFIG['image_size'])\n",
    "    print(f\"Using {len(tta_transforms)} TTA transforms\")\n",
    "else:\n",
    "    tta_transforms = [get_val_transform(CONFIG['image_size'])]\n",
    "    print(\"TTA disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Get Target Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for normalization statistics\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df['image_id'] = train_df['sample_id'].str.split('__').str[0]\n",
    "\n",
    "train_wide = train_df.pivot_table(\n",
    "    index='image_id',\n",
    "    columns='target_name',\n",
    "    values='target',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "target_stats = {}\n",
    "for target_name in TARGET_NAMES:\n",
    "    values = train_wide[target_name].values\n",
    "    target_stats[target_name] = {\n",
    "        'mean': float(np.mean(values)),\n",
    "        'std': float(np.std(values)) + 1e-8\n",
    "    }\n",
    "\n",
    "print(\"Target normalization statistics:\")\n",
    "for target_name, stats in target_stats.items():\n",
    "    print(f\"  {target_name:<20} mean: {stats['mean']:>8.2f}  std: {stats['std']:>8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Fold Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_models = []\n",
    "\n",
    "print(f\"Loading {N_FOLDS} fold models...\")\n",
    "for fold_idx in range(N_FOLDS):\n",
    "    checkpoint_path = Path(MODEL_BASE) / f'fold_{fold_idx}' / 'best_model.pth'\n",
    "    \n",
    "    print(f\"\\nFold {fold_idx + 1}/{N_FOLDS}:\")\n",
    "    print(f\"  Loading from: {checkpoint_path}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = RGBDepthFusionEncoder(\n",
    "        rgb_backbone=CONFIG['backbone'],\n",
    "        depth_model_path=DEPTH_MODEL_PATH,\n",
    "        fusion_type=CONFIG['fusion_type'],\n",
    "        dropout=CONFIG['dropout'],\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"  Val Loss: {checkpoint['best_val_loss']:.4f}\")\n",
    "    \n",
    "    fold_models.append(model)\n",
    "\n",
    "print(f\"\\nLoaded {len(fold_models)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Predictions with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(pred_dict, target_stats):\n",
    "    \"\"\"Denormalize predictions.\"\"\"\n",
    "    return {\n",
    "        name: (value * target_stats[name]['std']) + target_stats[name]['mean']\n",
    "        for name, value in pred_dict.items()\n",
    "    }\n",
    "\n",
    "all_fold_predictions = []\n",
    "\n",
    "for fold_idx, model in enumerate(fold_models):\n",
    "    print(f\"\\nFold {fold_idx + 1}/{N_FOLDS}...\")\n",
    "    fold_predictions = {name: [] for name in TARGET_NAMES}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tta_idx, tta_transform in enumerate(tta_transforms):\n",
    "            # Create dataset with TTA transform\n",
    "            test_dataset = BiomassTestDataset(\n",
    "                csv_path=TEST_CSV,\n",
    "                img_dir=TEST_IMG_DIR,\n",
    "                transform=tta_transform,\n",
    "                target_stats=target_stats\n",
    "            )\n",
    "            \n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                shuffle=False,\n",
    "                num_workers=CONFIG['num_workers']\n",
    "            )\n",
    "            \n",
    "            tta_preds = {name: [] for name in TARGET_NAMES}\n",
    "            \n",
    "            for batch in test_loader:\n",
    "                images = batch['image'].to(DEVICE)\n",
    "                predictions = model(images)\n",
    "                \n",
    "                batch_size = images.size(0)\n",
    "                for i in range(batch_size):\n",
    "                    pred_dict = {name: predictions[name][i].item() for name in TARGET_NAMES}\n",
    "                    pred_denorm = denormalize(pred_dict, target_stats)\n",
    "                    \n",
    "                    for name in TARGET_NAMES:\n",
    "                        tta_preds[name].append(pred_denorm[name])\n",
    "            \n",
    "            # Accumulate TTA predictions\n",
    "            if tta_idx == 0:\n",
    "                for name in TARGET_NAMES:\n",
    "                    fold_predictions[name] = tta_preds[name]\n",
    "            else:\n",
    "                for name in TARGET_NAMES:\n",
    "                    for i in range(len(tta_preds[name])):\n",
    "                        fold_predictions[name][i] += tta_preds[name][i]\n",
    "    \n",
    "    # Average TTA predictions\n",
    "    n_tta = len(tta_transforms)\n",
    "    for name in TARGET_NAMES:\n",
    "        fold_predictions[name] = [p / n_tta for p in fold_predictions[name]]\n",
    "    \n",
    "    all_fold_predictions.append(fold_predictions)\n",
    "    print(f\"  Generated predictions for {len(fold_predictions[TARGET_NAMES[0]])} samples\")\n",
    "\n",
    "print(f\"\\nGenerated predictions from all {len(fold_models)} folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ensemble and Apply Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across folds\n",
    "print(\"Averaging predictions across folds...\")\n",
    "n_samples = len(all_fold_predictions[0][TARGET_NAMES[0]])\n",
    "ensemble_predictions = {name: [] for name in TARGET_NAMES}\n",
    "\n",
    "for sample_idx in range(n_samples):\n",
    "    for name in TARGET_NAMES:\n",
    "        fold_preds = [fp[name][sample_idx] for fp in all_fold_predictions]\n",
    "        ensemble_predictions[name].append(np.mean(fold_preds))\n",
    "\n",
    "# Apply biological constraints\n",
    "print(\"Applying biological constraints...\")\n",
    "for sample_idx in range(n_samples):\n",
    "    # Clip negatives\n",
    "    for name in TARGET_NAMES:\n",
    "        ensemble_predictions[name][sample_idx] = max(0.0, ensemble_predictions[name][sample_idx])\n",
    "    \n",
    "    clover = ensemble_predictions['Dry_Clover_g'][sample_idx]\n",
    "    dead = ensemble_predictions['Dry_Dead_g'][sample_idx]\n",
    "    green = ensemble_predictions['Dry_Green_g'][sample_idx]\n",
    "    gdm = ensemble_predictions['GDM_g'][sample_idx]\n",
    "    total = ensemble_predictions['Dry_Total_g'][sample_idx]\n",
    "    \n",
    "    # Enforce GDM = Green + Clover\n",
    "    gdm_calc = green + clover\n",
    "    adjusted_gdm = (gdm + gdm_calc) / 2\n",
    "    if gdm_calc > 0:\n",
    "        scale = adjusted_gdm / gdm_calc\n",
    "        ensemble_predictions['Dry_Green_g'][sample_idx] = green * scale\n",
    "        ensemble_predictions['Dry_Clover_g'][sample_idx] = clover * scale\n",
    "    ensemble_predictions['GDM_g'][sample_idx] = adjusted_gdm\n",
    "    \n",
    "    # Enforce Total = GDM + Dead\n",
    "    total_calc = adjusted_gdm + dead\n",
    "    adjusted_total = (total + total_calc) / 2\n",
    "    if adjusted_total > adjusted_gdm:\n",
    "        ensemble_predictions['Dry_Dead_g'][sample_idx] = adjusted_total - adjusted_gdm\n",
    "    else:\n",
    "        ensemble_predictions['Dry_Dead_g'][sample_idx] = 0.0\n",
    "        adjusted_total = adjusted_gdm\n",
    "    ensemble_predictions['Dry_Total_g'][sample_idx] = adjusted_total\n",
    "\n",
    "print(\"\\nPredictions summary:\")\n",
    "for name in TARGET_NAMES:\n",
    "    values = ensemble_predictions[name]\n",
    "    print(f\"  {name:<15} mean: {np.mean(values):>8.2f}  min: {np.min(values):>8.2f}  max: {np.max(values):>8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test.csv to get sample_id ordering\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "test_image_ids = test_df['sample_id'].str.split('__').str[0].unique()\n",
    "\n",
    "# Create submission rows\n",
    "submission_rows = []\n",
    "for img_idx, image_id in enumerate(test_image_ids):\n",
    "    for name in TARGET_NAMES:\n",
    "        sample_id = f\"{image_id}__{name}\"\n",
    "        prediction = ensemble_predictions[name][img_idx]\n",
    "        submission_rows.append({'sample_id': sample_id, 'target': prediction})\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created!\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Constraint Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Constraint verification:\")\n",
    "for sample_idx in range(n_samples):\n",
    "    gdm = ensemble_predictions['GDM_g'][sample_idx]\n",
    "    gdm_calc = ensemble_predictions['Dry_Green_g'][sample_idx] + ensemble_predictions['Dry_Clover_g'][sample_idx]\n",
    "    total = ensemble_predictions['Dry_Total_g'][sample_idx]\n",
    "    total_calc = ensemble_predictions['GDM_g'][sample_idx] + ensemble_predictions['Dry_Dead_g'][sample_idx]\n",
    "    \n",
    "    print(f\"Sample {sample_idx}:\")\n",
    "    print(f\"  GDM diff: {abs(gdm - gdm_calc):.6f}\")\n",
    "    print(f\"  Total diff: {abs(total - total_calc):.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Submission ready: submission.csv\")\n",
    "print(\"RGB+Depth Fusion 5-Fold Ensemble with TTA\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
