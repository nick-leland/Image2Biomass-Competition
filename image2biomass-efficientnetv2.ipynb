{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSIRO Image2Biomass - EfficientNetV2-M with TTA\n",
    "\n",
    "This notebook generates predictions using an optimized EfficientNetV2-M model trained with:\n",
    "- Huber loss (delta=2.0)\n",
    "- Conservative augmentation\n",
    "- RMSprop optimizer\n",
    "- Test-Time Augmentation (4 flips)\n",
    "- Validation loss: 0.3147 (28% improvement over ResNet50)\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload the model checkpoint as a Kaggle Dataset named 'biomass-efficientnetv2-final'\n",
    "2. Add the competition data\n",
    "3. Run all cells to generate submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV = '/kaggle/input/csiro-biomass/test.csv'\n",
    "TEST_IMG_DIR = '/kaggle/input/csiro-biomass/test'\n",
    "TRAIN_CSV = '/kaggle/input/csiro-biomass/train.csv'\n",
    "TRAIN_IMG_DIR = '/kaggle/input/csiro-biomass/train'\n",
    "\n",
    "# Model checkpoint - UPDATE THIS PATH after uploading checkpoint\n",
    "CHECKPOINT_PATH = '/kaggle/input/biomass-efficientnetv2-final/pytorch/default/1/best_model.pth'\n",
    "\n",
    "# Target names\n",
    "TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "\n",
    "# Model config (from Optuna optimization - Trial 41)\n",
    "CONFIG = {\n",
    "    'backbone': 'tf_efficientnetv2_m',\n",
    "    'pretrained': True,\n",
    "    'dropout': 0.5,\n",
    "    'head_hidden_dim': 512,\n",
    "    'image_size': 512,\n",
    "    'batch_size': 8,  # Reduced for CPU/memory constraints\n",
    "    'num_workers': 2,\n",
    "    'use_tta': True  # Test-Time Augmentation\n",
    "}\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    \"\"\"Multi-task model for biomass prediction - supports any timm backbone.\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone='tf_efficientnetv2_m', num_targets=5, pretrained=True,\n",
    "                 dropout=0.5, head_hidden_dim=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained backbone\n",
    "        self.backbone = timm.create_model(backbone, pretrained=pretrained, num_classes=0)\n",
    "        backbone_features = self.backbone.num_features\n",
    "        \n",
    "        # Create prediction heads\n",
    "        self.heads = nn.ModuleDict({\n",
    "            target_name: self._make_head(backbone_features, head_hidden_dim, dropout)\n",
    "            for target_name in TARGET_NAMES\n",
    "        })\n",
    "    \n",
    "    def _make_head(self, in_features, hidden_dim, dropout):\n",
    "        \"\"\"Create a prediction head.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        features = self.backbone(x)\n",
    "        outputs = {\n",
    "            target_name: self.heads[target_name](features).squeeze(-1)\n",
    "            for target_name in TARGET_NAMES\n",
    "        }\n",
    "        return outputs\n",
    "\n",
    "print(\"Model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassTestDataset(Dataset):\n",
    "    \"\"\"Test dataset for biomass prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path, img_dir, transform=None, target_stats=None):\n",
    "        self.csv_path = csv_path\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.target_stats = target_stats\n",
    "        \n",
    "        # Load CSV\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df['image_id'] = self.df['sample_id'].str.split('__').str[0]\n",
    "        self.image_ids = self.df['image_id'].unique()\n",
    "        self.image_paths = self.df.groupby('image_id')['image_path'].first().to_dict()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_filename = Path(self.image_paths[image_id]).name\n",
    "        image_path = self.img_dir / image_filename\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'image_id': image_id\n",
    "        }\n",
    "\n",
    "print(\"Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get Target Statistics from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data to compute normalization statistics\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df['image_id'] = train_df['sample_id'].str.split('__').str[0]\n",
    "\n",
    "# Pivot to wide format\n",
    "train_wide = train_df.pivot_table(\n",
    "    index='image_id',\n",
    "    columns='target_name',\n",
    "    values='target',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "# Compute statistics\n",
    "target_stats = {}\n",
    "for target_name in TARGET_NAMES:\n",
    "    values = train_wide[target_name].values\n",
    "    target_stats[target_name] = {\n",
    "        'mean': float(np.mean(values)),\n",
    "        'std': float(np.std(values)) + 1e-8\n",
    "    }\n",
    "\n",
    "print(\"Target normalization statistics:\")\n",
    "for target_name, stats in target_stats.items():\n",
    "    print(f\"  {target_name:<20} mean: {stats['mean']:>8.2f}  std: {stats['std']:>8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TTA Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tta_transforms(image_size=512):\n",
    "    \"\"\"Get test-time augmentation transforms (4 flips).\"\"\"\n",
    "    \n",
    "    # Original (no flip)\n",
    "    transform_original = A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    # Horizontal flip\n",
    "    transform_hflip = A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    # Vertical flip\n",
    "    transform_vflip = A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    # Both flips\n",
    "    transform_hvflip = A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    return [\n",
    "        transform_original,\n",
    "        transform_hflip,\n",
    "        transform_vflip,\n",
    "        transform_hvflip\n",
    "    ]\n",
    "\n",
    "print(\"TTA transforms defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Model and Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(f\"Creating model: {CONFIG['backbone']}...\")\n",
    "model = MultiTaskModel(\n",
    "    backbone=CONFIG['backbone'],\n",
    "    num_targets=len(TARGET_NAMES),\n",
    "    pretrained=False,  # We'll load trained weights\n",
    "    dropout=CONFIG['dropout'],\n",
    "    head_hidden_dim=CONFIG['head_hidden_dim']\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Load checkpoint\n",
    "print(f\"Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Checkpoint loaded successfully!\")\n",
    "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Best Val Loss: {checkpoint['best_val_loss']:.4f}\")\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_predictions(pred_dict, target_stats):\n",
    "    \"\"\"Denormalize predictions back to original scale.\"\"\"\n",
    "    denormalized = {}\n",
    "    for target_name, value in pred_dict.items():\n",
    "        stats = target_stats[target_name]\n",
    "        denormalized[target_name] = (value * stats['std']) + stats['mean']\n",
    "    return denormalized\n",
    "\n",
    "def enforce_constraint(predictions, method='average'):\n",
    "    \"\"\"Enforce constraint: Dry_Total = Dry_Clover + Dry_Dead + Dry_Green\"\"\"\n",
    "    enforced = {}\n",
    "    \n",
    "    for image_id, pred_dict in predictions.items():\n",
    "        pred = pred_dict.copy()\n",
    "        \n",
    "        clover = pred['Dry_Clover_g']\n",
    "        dead = pred['Dry_Dead_g']\n",
    "        green = pred['Dry_Green_g']\n",
    "        total = pred['Dry_Total_g']\n",
    "        \n",
    "        component_sum = clover + dead + green\n",
    "        \n",
    "        if method == 'average':\n",
    "            # Average the predicted total and sum of components\n",
    "            new_total = (total + component_sum) / 2\n",
    "            \n",
    "            # Distribute discrepancy proportionally\n",
    "            if component_sum > 0:\n",
    "                scale = new_total / component_sum\n",
    "                pred['Dry_Clover_g'] = clover * scale\n",
    "                pred['Dry_Dead_g'] = dead * scale\n",
    "                pred['Dry_Green_g'] = green * scale\n",
    "                pred['Dry_Total_g'] = new_total\n",
    "            else:\n",
    "                pred['Dry_Total_g'] = 0.0\n",
    "        \n",
    "        enforced[image_id] = pred\n",
    "    \n",
    "    return enforced\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Predictions with TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['use_tta']:\n",
    "    print(\"Using Test-Time Augmentation (4 transforms)\")\n",
    "    tta_transforms = get_tta_transforms(CONFIG['image_size'])\n",
    "    \n",
    "    # Store predictions from all TTA iterations\n",
    "    all_predictions = {target: {} for target in TARGET_NAMES}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tta_idx, tta_transform in enumerate(tta_transforms):\n",
    "            print(f\"  TTA {tta_idx + 1}/{len(tta_transforms)}...\")\n",
    "            \n",
    "            # Create dataset with this TTA transform\n",
    "            test_dataset = BiomassTestDataset(\n",
    "                csv_path=TEST_CSV,\n",
    "                img_dir=TEST_IMG_DIR,\n",
    "                transform=tta_transform,\n",
    "                target_stats=target_stats\n",
    "            )\n",
    "            \n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                shuffle=False,\n",
    "                num_workers=CONFIG['num_workers']\n",
    "            )\n",
    "            \n",
    "            for batch in test_loader:\n",
    "                images = batch['image'].to(DEVICE)\n",
    "                image_ids = batch['image_id']\n",
    "                \n",
    "                # Get predictions\n",
    "                pred = model(images)\n",
    "                \n",
    "                # Store predictions\n",
    "                for i, image_id in enumerate(image_ids):\n",
    "                    for target_name in TARGET_NAMES:\n",
    "                        if image_id not in all_predictions[target_name]:\n",
    "                            all_predictions[target_name][image_id] = []\n",
    "                        all_predictions[target_name][image_id].append(\n",
    "                            pred[target_name][i].cpu().item()\n",
    "                        )\n",
    "    \n",
    "    # Average predictions\n",
    "    predictions = {}\n",
    "    for image_id in all_predictions[TARGET_NAMES[0]].keys():\n",
    "        pred_dict = {\n",
    "            target_name: np.mean(all_predictions[target_name][image_id])\n",
    "            for target_name in TARGET_NAMES\n",
    "        }\n",
    "        # Denormalize\n",
    "        pred_dict = denormalize_predictions(pred_dict, target_stats)\n",
    "        predictions[image_id] = pred_dict\n",
    "    \n",
    "    print(f\"Generated TTA predictions for {len(predictions)} images\")\n",
    "\n",
    "else:\n",
    "    print(\"Using single inference (no TTA)\")\n",
    "    # Standard inference without TTA\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(CONFIG['image_size'], CONFIG['image_size']),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    test_dataset = BiomassTestDataset(\n",
    "        csv_path=TEST_CSV,\n",
    "        img_dir=TEST_IMG_DIR,\n",
    "        transform=val_transform,\n",
    "        target_stats=target_stats\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Generating predictions\"):\n",
    "            images = batch['image'].to(DEVICE)\n",
    "            image_ids = batch['image_id']\n",
    "            \n",
    "            pred = model(images)\n",
    "            \n",
    "            for i, image_id in enumerate(image_ids):\n",
    "                pred_dict = {\n",
    "                    target_name: pred[target_name][i].cpu().item()\n",
    "                    for target_name in TARGET_NAMES\n",
    "                }\n",
    "                pred_dict = denormalize_predictions(pred_dict, target_stats)\n",
    "                predictions[image_id] = pred_dict\n",
    "    \n",
    "    print(f\"Generated predictions for {len(predictions)} images\")\n",
    "\n",
    "# Apply constraint enforcement\n",
    "print(\"Applying constraint enforcement...\")\n",
    "predictions = enforce_constraint(predictions, method='average')\n",
    "\n",
    "# Check constraint violations\n",
    "violations = []\n",
    "for image_id, pred in predictions.items():\n",
    "    total = pred['Dry_Total_g']\n",
    "    component_sum = pred['Dry_Clover_g'] + pred['Dry_Dead_g'] + pred['Dry_Green_g']\n",
    "    violation = abs(total - component_sum)\n",
    "    violations.append(violation)\n",
    "\n",
    "print(f\"Constraint violations:\")\n",
    "print(f\"  Mean: {np.mean(violations):.6f}g\")\n",
    "print(f\"  Max: {np.max(violations):.6f}g\")\n",
    "print(f\"  All exact: {all(v < 1e-6 for v in violations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test.csv to get correct sample_id ordering\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Create submission rows\n",
    "submission_rows = []\n",
    "for _, row in test_df.iterrows():\n",
    "    sample_id = row['sample_id']\n",
    "    image_id = sample_id.split('__')[0]\n",
    "    target_name = row['target_name']\n",
    "    \n",
    "    # Get prediction\n",
    "    pred_value = predictions[image_id][target_name]\n",
    "    \n",
    "    submission_rows.append({\n",
    "        'sample_id': sample_id,\n",
    "        'target': pred_value\n",
    "    })\n",
    "\n",
    "# Create DataFrame and save\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created!\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission_df.head(10))\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(submission_df['target'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Display Predictions Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPredictions by target:\")\n",
    "for target_name in TARGET_NAMES:\n",
    "    values = [pred[target_name] for pred in predictions.values()]\n",
    "    print(f\"  {target_name:<20} mean: {np.mean(values):>8.2f}  \"\n",
    "          f\"min: {np.min(values):>8.2f}  max: {np.max(values):>8.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Submission file ready: submission.csv\")\n",
    "print(\"Model: EfficientNetV2-M with TTA (Val Loss: 0.3147)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
